{
 "metadata": {
  "name": "",
  "signature": "sha256:2d7c071c85249834943b0faf84e1cbff93226952e9609ffd45ad5b2ff65c16d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir\n",
      "from os.path import isfile, join\n",
      "from ttp import ttp\n",
      "from itertools import chain\n",
      "\n",
      "import json\n",
      "import csv\n",
      "\n",
      "from textblob import TextBlob\n",
      "from textblob.sentiments import NaiveBayesAnalyzer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named ttp",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-adb8a12dbfb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mttp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mttp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mttp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named ttp"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "UPPERLETTERS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
      "LETTERS_AND_SPACE = UPPERLETTERS + UPPERLETTERS.lower() + ' \\t\\n'\n",
      "\n",
      "def loadDictionary():\n",
      "    dictionaryFile = open('dictionary.txt')\n",
      "    englishWords = {}\n",
      "    for word in dictionaryFile.read().split('\\n'):\n",
      "        englishWords[word] = None\n",
      "    dictionaryFile.close()\n",
      "    return englishWords\n",
      "\n",
      "ENGLISH_WORDS = loadDictionary()\n",
      "\n",
      "def getEnglishCount(message):\n",
      "    message = message.upper()\n",
      "    message = removeNonLetters(message)\n",
      "    possibleWords = message.split()\n",
      "\n",
      "    if possibleWords == []:\n",
      "        # no words at all, so return 0.0\n",
      "        return 0.0, ''  \n",
      "\n",
      "    matches = 0\n",
      "    all_words = []\n",
      "    for word in possibleWords:\n",
      "        if word in ENGLISH_WORDS:\n",
      "            matches += 1\n",
      "            all_words.append(word + ' ')\n",
      "    return float(matches) / len(possibleWords), ''.join(all_words).lower()\n",
      "\n",
      "\n",
      "def removeNonLetters(message):\n",
      "    lettersOnly = []\n",
      "    for symbol in message:\n",
      "        if symbol in LETTERS_AND_SPACE:\n",
      "            lettersOnly.append(symbol)\n",
      "    return ''.join(lettersOnly)\n",
      "\n",
      "\n",
      "def isEnglish(message, wordPercentage=20, letterPercentage=85):\n",
      "    # By default, 20% of the words must exist in the dictionary file, and\n",
      "    # 85% of all the characters in the message must be letters or spaces\n",
      "    # (not punctuation or numbers).\n",
      "    cnt, sentence = getEnglishCount(message)\n",
      "    words_match = cnt * 100 >= wordPercentage\n",
      "    numLetters = len(removeNonLetters(message))\n",
      "    messageLettersPercentage = float(numLetters) / len(message) * 100\n",
      "    letters_match = messageLettersPercentage >= letterPercentage\n",
      "    return words_match and letters_match, sentence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jsons_to_tuple(twi_path):\n",
      "    twi_jsons = [ f for f in listdir(twi_path) if isfile(join(twi_path,f)) ][:100]\n",
      "\n",
      "    all_ids = []\n",
      "    for f in twi_jsons:\n",
      "        with open('%s%s' %(twi_path, f)) as json_file:\n",
      "            tweets = json.load(json_file).values()\n",
      "            for tweet in tweets:\n",
      "                content = tweet['content']\n",
      "                \n",
      "                is_english, new_content = isEnglish(content, 20, 65)\n",
      "                if is_english:\n",
      "                    if float(tweet['lat']) != 0 and float(tweet['lon']) != 0:\n",
      "                        if tweet['tweet_id'] not in all_ids:\n",
      "                            all_ids.append(tweet['tweet_id'])\n",
      "                            yield tweet['tweet_id'], tweet['lat'], tweet['lon'], new_content"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twi_path = '../python/twitter/'\n",
      "tweets = jsons_to_tuple(twi_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sentiment(text):\n",
      "    blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
      "    return blob.sentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#with open('csv/sentiment_tweets.csv', 'wb') as fp:\n",
      "#writer = csv.writer(fp, delimiter=',')\n",
      "#writer.writerow( ('lat', 'lon', 'tweet', 'sentiment', 'pos', 'neg') )\n",
      "for tweet in tweets: \n",
      "    tid, lat, lon, content = tweet\n",
      "    sentiment, pos, neg = get_sentiment(content)\n",
      "    #writer.writerow([lat, lon, content, sentiment, pos, neg])\n",
      "    with open('json_twitter/%ssentiment_tweet.json' %(tid), 'w' ) as f:\n",
      "        f.write( json.dumps({'lat':lat, 'lon':lon, 'tweet':content, 'sentiment':sentiment, 'pos':pos, 'neg':neg}))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}