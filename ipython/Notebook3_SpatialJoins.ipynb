{
 "metadata": {
  "name": "",
  "signature": "sha256:40b87f44a75a608df2dd4d3aa031d188c049fdc38c5608d26cade8ef2788fc13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Shapefiles from Analyzed Twitter Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the sentiment and topic analyses of the twitter data that we collected, we turn the results into a map-able data format (GIS shapefiles).  Using from these shapefiles, we then intersect them with neighborhood boundaries in NYC to see which neighborhood these tweets occurred in. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import os\n",
      "import math\n",
      "import csv\n",
      "\n",
      "from os.path import isfile,join\n",
      "import shapefile\n",
      "import shapely\n",
      "import csv\n",
      "from pyproj import Proj, transform\n",
      "from shapely.geometry import Polygon\n",
      "from shapely.geometry import Point"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Create shapefiles from twitter jsons\n",
      "## Retrieve all the filenames from the directory where we've saved the twitter analysis.\n",
      "## Use the Shapefile module in Python, which is able to read and write shapefiles (map data)\n",
      "## in Python.\n",
      "\n",
      "\n",
      "path_tw = 'json_twitter/'\n",
      "path_topic = 'json_topic/'\n",
      "files = os.listdir(path_topic)\n",
      "w = shapefile.Writer(shapefile.POINT)\n",
      "\n",
      "## Create attribute table for the shapefiles that retains all the info from the json\n",
      "w.field('tweet')\n",
      "w.field('hashtags')\n",
      "w.field('lon')\n",
      "w.field('topic')\n",
      "w.field('frequency')\n",
      "w.field('lat')\n",
      "w.field('NTA')\n",
      "w.field('NTACODE')\n",
      "\n",
      "## Open each file within the directory in which we've stored all the analyzed tweets and compile\n",
      "## all the tweets, which are stored as individual tweets, into a single file.\n",
      "for item in files: \n",
      "    with open('%s%s' %(path_topic, item)) as f: \n",
      "        text = f.read()\n",
      "        data = json.loads(text)\n",
      "        w.point(data['lat'],data['lon'])\n",
      "        w.record((data['tweet']).encode('utf-8'),data['hashtags'], data['lon'], data['topic'], data['frequency'], data['lat'],'empty','empty')\n",
      "\n",
      "        w.save('topicshapes')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Edits the attribute tables of the shapefiles we've created in order encode neighborhoods for each tweet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load the a shapefile of polygons and convert it to shapely polygon objects\n",
      "\n",
      "## This is file containing the neighborhood boundaries\n",
      "polygons_sf = shapefile.Reader(\"./nynta_14c/nynta.shp\")\n",
      "polygon_shapes = polygons_sf.shapes()\n",
      "polygon_points = [q.points for q in polygon_shapes ]\n",
      "\n",
      "## Load the python database reader for GIS data\n",
      "from dbfpy import dbf\n",
      "\n",
      "## Load databases\n",
      "db_NTA = dbf.Dbf(\"./nynta_14c/nynta.dbf\")\n",
      "db_tweet = dbf.Dbf(\"./Sentiment_shapes/tweetshapes.dbf\")\n",
      "db_topic = dbf.Dbf(\"./Topics_shapes/topicshapes.dbf\")\n",
      "\n",
      "\n",
      "def joinpts(filename,database):\n",
      "    ## Code for points with x,y coordinates for our data needing conversion into \n",
      "    ## latitudes and longitudes:\n",
      "    p = Proj(init = \"esri:102718\",preserve_units=True)\n",
      "    for i in polygon_points: \n",
      "        for j in i: \n",
      "            j[0],j[1] = p(j[0],j[1], inverse =True)\n",
      "            \n",
      "    # Define polygons with new projections\n",
      "    polygons = [Polygon(q) for q in polygon_points]\n",
      "\n",
      "    #Load the shapefile of points and convert it to shapely point objects\n",
      "    points_sf = shapefile.Reader(filename)\n",
      "    point_shapes = points_sf.shapes()\n",
      "    point_coords= [q.points[0] for q in point_shapes ]\n",
      "    points = [Point(q.points[0]) for q in point_shapes ]\n",
      "    \n",
      "    #Switch order of the coordinates, if needed:\n",
      "    # point_coords = map(lambda x: [x[1],x[0]],point_coords)\n",
      "    \n",
      "    # Create new shapefile points from the latitude and longitude data:\n",
      "    new_points = [None]*len(points)\n",
      "    for i in range(len(new_points)):\n",
      "        new_points[i] = shapely.geometry.Point(point_coords[i])\n",
      "        \n",
      "    # Find matches and join the neighorhood to the tweet\n",
      "    for i in range(len(new_points)): #Iterate through each point\n",
      "        for j in range(len(polygons)):\n",
      "            if new_points[i].within(polygons[j]):\n",
      "\n",
      "                rec_tweet = database[i]\n",
      "                ## Add new fields to the data that shows which neighborhood (if any) the\n",
      "                ## data point sits in.\n",
      "                rec_tweet['NTA'] = db_NTA[j]['NTANAME']\n",
      "                rec_tweet['NTACODE'] = db_NTA[j]['NTACODE']\n",
      "                rec_tweet.store()\n",
      "                del rec_tweet\n",
      "                \n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## execute function for shapefiles we want to join\n",
      "joinpts('topicshapes.shp',db_topic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}