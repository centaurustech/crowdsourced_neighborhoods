{
 "metadata": {
  "name": "",
  "signature": "sha256:f98a58b810d3819c9e8d19beb1ce85267b4736aeb366e8ec9af2bb4014253b23"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CROWDSOURCED NEIGHBORHOODS"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Wenfei Xu, Phil Cheng, Hector Flores, Carlos Sandoval Olascoaga"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Instructions are on: instructions.txt"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The code of the project is hosted on: https://github.com/cesandoval/crowdsourced_neighborhoods"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "All the files are hosted on: https://drive.google.com/folderview?id=0B7-4LRflMYObQ3RjQVR5cTZldmc&usp=sharing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The ipython notebooks with the required directories for execution are on: https://drive.google.com/folderview?id=0B7-4LRflMYObRkttWTcxY0lZWWM&usp=sharing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The ipython notebook have been uploaded to the isites website, with Carlos Sandoval Olascoaga's account"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "OVERVIEW: \n",
      "A NEIGHBORHOOD RANKING SYSTEM THAT RESONATES WITH OUR RATIONAL & EMOTIONAL NEEDS "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our project creates a ranking system for the 195 neighborhoods in New York City that helps users find the one that best matches their preferences.  To do that, our team has developed a composite weighted score with urban spatial data and social media data to rank all NYC neighborhoods. We have used conventional urban data, like median home values or access to transit, but also social media data to gain insight on the \u201cinner soul\u201d of NYC neighborhoods. \n",
      " \n",
      "Given the diversity of users and preferences, the user will be able to modify the scores assigned to each of the dimensions by which the neighborhoods are ranked in order to produce tailored results. The end product for our users is a list of neighborhoods that ranks them according to what they care the most and that will help make a better decision on which NYC neighborhood to live in.  To get there, our process included three main streams of work."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      " 1. Social Media Data Scraping & Meaning-Making"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The inclusion of the social media data has implied a significant effort from our team both in order to scrape the data and implement data science tools to extract meaningful insights from it. In particular, besides implementing exploratory data analysis and machine learning techniques on our urban data, we have used natural language processing (NLP) for our social media data. Our team chose to implement both sentiment analysis and latent topic modeling (LTA) for the tweets we scraped from all neighborhoods in NYC.  Using a combination of desktop server and AWS distributed computing,  the analysis resulted in significant insights on the mood of each neighborhood (in a positive/negative classification), but also in the popularity of topics people engage with."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Geoprocessing Conventional Stats & Social Media Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data collected from government portals and the Social Media come in a mixed of locational designations such as street addresses, block codes and geo-coordinates.  To combine various data into a comparable form across neighborhoods, we employed Python geoprocessing libraries such as Shapely and GDAL to spatially join the data, produce GEOJSON polygons for mapping."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Web Mapping & Front-End Production"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To maximize the accessibility of this platform and convey the multidimensionality of ranking input, we setup our webmap using the JavaScript D3 library, which is ideal for constructing data-driven interactions within the modern browser environment.  This process reduces the otherwise cumbersome map files into light-weight browser-ready vector graphics, and sets up the visual parameters for displaying data based on the user preference."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "iPython Notebook Organization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Filenames and description (Organized roughly by workflow sequence)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "00. Overview.ipynb: Project Overview, References Work, Libraries and Summary of Analyses"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "01. GIS_DataPrep.ipynb: Processing geographical information (GIS) data for mapping urban statistics "
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "02. Web_scrapping.ipynb: Processing social media data."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "03. Semantic_analysis.ipynb: Semantic data analysis of social media data through machine learning"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "04. Exploratory_analysis.ipynb: Exploratory Data Analysis of urban statistics and datasets."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "05. Final_analysis.ipynb: Development of neighborhood scores through analysis of several data sources."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "06. Web-visualization.ipynb: Code written in D3 to visualize the overall results of the neighborhood score on a webmap."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Related Work & Inspirations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Open Data movement has gained significant progress in the past few years.  Government agencies, such as NYC Open Data (https://nycopendata.socrata.com/) and the Metro Chicago Data (https://www.metrochicagodata.org/), for example, publish the many previously difficult-to-access data in a user-friendly fashion.  In turn, citizens, businesses and non-governmental organizations are able to innovate applications of the data relevant to their goals.  For example, I Quant NY (http://iquantny.tumblr.com/) represents one of the many individual efforts to map out for the general public various new services such as Free Wifi Payphones and also the current usage dynamics of the Citi Bike program.   Trulia.com, on the other hand, aggregates relevant data such as crime rate, public transit availability and property value trends to help home buyers or sellers make informed decisions. \n",
      "\n",
      "The rise of social media such as Twitter, Instagram and Foursquare also enable us see the cities in through both individual and collective expressions, through their choices of destinations and their photographs.  They provide a non-traditional layer of information not found in official statistics.  To take advantage of that, our project made specific use of Twitter and Instagram hashtags as a proxy to understand the general difference in interests across neighborhoods of New York City.  Using the methodology of Topic Modeling learned from various sources listed below, we were able to cluster social media feeds (approx. 600,000 tweets) into related topics, isolate six general themes that represent non-traditional measure of neighborhoods. \n",
      "\n",
      "For communicating the data to the general public, D3 interactive visualizations of Mike Bostock (http://bost.ocks.org/mike/), published mostly via the NY Times, provided us the framework for visualizing findings in the most sharable and reader-friendly fashion.  For this reason, we departed from using the traditional ArcGIS mapping software to learn mapping techniques for the web from scratch."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Social Media Processing References:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Empirical Study of Topic Modeling in Twitter \n",
      "(http://snap.stanford.edu/soma2010/papers/soma2010_12.pdf) \n",
      "\n",
      "Extracting Topic Trends and Connection: Semantic Analysis and Topic Linking in Twitter and Wikipedia Datasets (http://snap.stanford.edu/class/cs224w-2012/projects/cs224w-004-final.v01.pdf)\n",
      "\n",
      "Mapping the World\u2019s Photos (http://dl.acm.org/citation.cfm?id=1526812)\n",
      "\n",
      "Cartography and Geographic Information Science (http://www.tandfonline.com/toc/tcag20/current#.VIiqkmTF-MA)\n",
      "\n",
      "Characterizing Urban Landscapes using Geolocated Tweets\n",
      "(http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6406289&tag=1)\n",
      "\n",
      "An Empirical Study of Geographic User Activity Patterns in Foursquare\n",
      "(http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/download/2831/3241)\n",
      "\n",
      "Hoodsqure: Modeling and Recommending Neighborhoods in Location-based Social Networks\n",
      "(http://arxiv.org/abs/1308.3657)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Language Processing, Visualization & Geoprocessing Libraries Used:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prj2EPSG:  Convert map projection files EPSG codes (http://prj2epsg.org/search)\n",
      "\n",
      "Shapely: Python geoprocessing library (https://pypi.python.org/pypi/Shapely)\n",
      "\n",
      "GDAL:  Python library for processing geospatial data into GEOJSON and TOPOJSON formats. (www.gdal.org)\n",
      "\n",
      "Caged\u2019s Blocks: library of D3 tools (http://bl.ocks.org/Caged)\n",
      "\n",
      "Mike Bostock: library of D3 tools (http://bost.ocks.org/mike/)\n",
      "\t\n",
      "Gemsim: Topic Modeling for Humans  (https://radimrehurek.com/gensim/)\n",
      "\n",
      "PyProj: cartographic transformations and geodetic computations  (pypi.python.org/pypi/pyproj)\n",
      "\n",
      "NLTK 3.0: Python Natural Lanugage Processing Toolkit (http://www.nltk.org/)\n",
      "\t\n",
      "TextBlob: Python library for process textual data (http://textblob.readthedocs.org/en/dev/)\n",
      "\t\n",
      "PyShP: Python support for ESRO Shapefile format (https://pypi.python.org/pypi/pyshp)\n",
      "\n",
      "DBFPY:  Python module for accessing dBase files (http://dbfpy.sourceforge.net/)\n",
      "\t\n",
      "Twython: Python wrapper for Twitter API (https://pypi.python.org/pypi/twython)\n",
      "\n",
      "Boto: Python interface for Amazon Web Services (https://boto.readthedocs.org/en/latest/)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Sources"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Our date come from mainly two categories of sources.  Social Media feeds provide us a view of the activities, ideas and discussions that concern people in different neighborhoods:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Twitter: Twitter API. Content: Tweets, users, location.\n",
      "\n",
      "Foursquare: Foursquare API. Content: Establishments, trending venues, ratings,users, venue types, location.\n",
      "\n",
      "Instagram: Instagram API. Content: Location, tags."
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Official Statistics from government portals and established websites provide us the conventional data that offer comparison of the general socio-economic conditions across neighborhoods:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Social and Economic Data (NYC Open Data)\n",
      "\n",
      "Crime Data: Trulia API. Content: Location, crime types.\n",
      "\n",
      "GIS Spatial / Tabular Data (e.g. home value, land-use, income, poverty rate, etc)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploratory Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "todo"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Final Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using Gensim Topic Modeling tools, we were able to cluster tweets that are found to be related to each other based on the association of keywords and hashtags.  Concretely, Gensim provided us a list of keywords (e.g. \u201cferguson\u201d) each tagged with a coefficient(e.g. 0.021) indicating the proportion of tweets within the the given cluster that\u2019s about the Ferguson incident.  By adding up the coefficients of related words such as \u201cferguson\u201d, \u201cmikebrown\u201d and \u201cprotest\u201d, we are able to infer the total proportion of the tweets that relates to a broader topic such as \u201cSocial Justice\u201d.  Likewise, keywords like \u201carchitecture\u201d and \u201cstreetart\u201d tell us about the tendency of people tweeting about \u201cPublic Space\u201d.  Given the sums of coefficients that indicate the broad topics being discussed on Twitter, we are able to map them across neighborhoods, retabulate the numbers to infer the occurrences of tweets that are about the six topics we aim to model, which are \u201cfashion\u201d, \u201cfoodie\u201d, \u201cmusic\u201d, \u201cnight life\u201d, \u201csocial justice\u201d and \u201cpublic space\u201d.  \n",
      "\n",
      "If given more time to refine the modelled topics, we would propose running a parallel modeling exercise by extracting trend topics and keywords from New York Times articles that fall under one of our target topics.  For example, keywords extracted from a large set of recent fashion-related articles would provide us a richer set of target keywords to search for in the pool of tweets, and therefore provide an alternative way to categorize each tweet.   We would be interested in discovering how Topic Modeling approached through scrapping live keywords from the news would differ from Topic Modeling approached through Gensim\u2019s semantic approach without the aid of popular keywords. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}